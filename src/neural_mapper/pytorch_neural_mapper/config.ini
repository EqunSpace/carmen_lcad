##TODO
# normalize [0,1]
# colocar entre -1 e 1 usar Subtrair a media e dividir pelo desvio padrao
#Test function
#
[DATASET]
train_path = /dados/neural_mapper/data_13-08-19/data/
train_list = /dados/neural_mapper/data_13-08-19/train_list.txt
target_path = /dados/neural_mapper/data_13-08-19/labels/
test_path = /dados/neural_mapper/data_13-08-19/data/
test_list = /dados/neural_mapper/data_13-08-19/test_list.txt
channels = 5
img_width = 600
img_height = 600
shuffle_data = on

#Para subtrair a media e dividir pelo desvio padrao
dataset_mean = 
dataset_std =

[DNN]
use_cuda = 1
device = 0
classes = 3
use_trained_model =
#batch will load for each label 5 inputs images, total batch = batch_size * 5
batch_size = 5
epochs = 1000

learning_rate = 0.001

#momentum = 0.9

step_size = 50
decay_rate = 2
dropout_prob = 0.25

#torch.manual_seed() reprodutibilidade
manual_seed = 1
#each X epochs save model       
interval_save_model = 50
save_models = /dados/neural_mapper/data_13-08-19/results/models/
save_log_files = /dados/neural_mapper/data_13-08-19/results/

#max_velodyne_hight 
max_normalize_mean = 1.852193

#max_velodyne_hight 
max_normalize_max = 1.852193

#max_value_above_gound
max_normalize_min = -10
#This value is computed 
max_normalize_std = 15
max_normalize_numb = 
